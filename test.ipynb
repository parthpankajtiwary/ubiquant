{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a5a28b-7dfb-43c9-97af-7a261ae3169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from data.PurgedGroupTimeSeriesSplit import \\\n",
    "    PurgedGroupTimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a8b5b0-b3c7-49d4-9b7f-0856df753946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded...\n"
     ]
    }
   ],
   "source": [
    "scores = dict()\n",
    "df = pd.read_csv('input/train.csv')\n",
    "\n",
    "print('data loaded...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2be7da4-60e4-4b38-9624-62fd66d6fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "class GroupTimeSeriesSplit:\n",
    "    \"\"\"\n",
    "    Custom class to create a Group Time Series Split. We ensure\n",
    "    that the time id values that are in the testing data are not a part\n",
    "    of the training data & the splits are temporal\n",
    "    \"\"\"\n",
    "    def __init__(self, n_folds: int, holdout_size: int, groups: str) -> None:\n",
    "        self.n_folds = n_folds\n",
    "        self.holdout_size = holdout_size\n",
    "        self.groups = groups\n",
    "\n",
    "    def split(self, X) -> Tuple[np.array, np.array]:\n",
    "        # Take the group column and get the unique values\n",
    "        unique_time_ids = np.unique(self.groups.values)\n",
    "\n",
    "        # Split the time ids into the length of the holdout size\n",
    "        # and reverse so we work backwards in time. Also, makes\n",
    "        # it easier to get the correct time_id values per\n",
    "        # split\n",
    "        array_split_time_ids = np.array_split(\n",
    "            unique_time_ids, len(unique_time_ids) // self.holdout_size\n",
    "        )[::-1]\n",
    "\n",
    "        # Get the first n_folds values\n",
    "        array_split_time_ids = array_split_time_ids[:self.n_folds]\n",
    "\n",
    "        for time_ids in array_split_time_ids:\n",
    "            # Get test index - time id values that are in the time_ids\n",
    "            test_condition = X['time_id'].isin(time_ids)\n",
    "            test_index = X.loc[test_condition].index\n",
    "\n",
    "            # Get train index - The train index will be the time\n",
    "            # id values right up until the minimum value in the test\n",
    "            # data - we can also add a gap to this step by\n",
    "            # time id < (min - gap)\n",
    "            train_condition = X['time_id'] < (np.min(time_ids))\n",
    "            train_index = X.loc[train_condition].index\n",
    "\n",
    "            yield train_index, test_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca4e04a4-d70c-42cb-8d07-9ed294282d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum:  3141410\n",
      "Frac:  0.18670773703480403\n",
      "FOLD: 0\n",
      "Train:\n",
      "Shape: (2647164,)\n",
      "0 -> 1068\n",
      "\n",
      "Val:\n",
      "Shape: (494246,)\n",
      "1069 -> 1219\n",
      "\n",
      "Sum:  2647164\n",
      "Frac:  0.21583305124875818\n",
      "FOLD: 1\n",
      "Train:\n",
      "Shape: (2177243,)\n",
      "0 -> 917\n",
      "\n",
      "Val:\n",
      "Shape: (469921,)\n",
      "918 -> 1068\n",
      "\n",
      "Sum:  2177243\n",
      "Frac:  0.2519474321266643\n",
      "FOLD: 2\n",
      "Train:\n",
      "Shape: (1739085,)\n",
      "0 -> 766\n",
      "\n",
      "Val:\n",
      "Shape: (438158,)\n",
      "767 -> 917\n",
      "\n",
      "Sum:  1739085\n",
      "Frac:  0.29844865741445886\n",
      "FOLD: 3\n",
      "Train:\n",
      "Shape: (1339356,)\n",
      "0 -> 615\n",
      "\n",
      "Val:\n",
      "Shape: (399729,)\n",
      "616 -> 766\n",
      "\n",
      "Sum:  1339356\n",
      "Frac:  0.3638410381580515\n",
      "FOLD: 4\n",
      "Train:\n",
      "Shape: (982047,)\n",
      "0 -> 464\n",
      "\n",
      "Val:\n",
      "Shape: (357309,)\n",
      "465 -> 615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gtss = GroupTimeSeriesSplit(n_folds=5, holdout_size=150, groups=df['time_id'])\n",
    "for fold, (tr, val) in enumerate(gtss.split(df)):\n",
    "    print('Sum: ', len(tr) + len(val))\n",
    "    print('Frac: ', len(val)/len(tr))\n",
    "    print('FOLD:', fold)\n",
    "    print('Train:')\n",
    "    print('Shape:', tr.shape)\n",
    "    print(np.min(df.iloc[tr].time_id), '->', np.max(df.iloc[tr].time_id))\n",
    "    print()\n",
    "\n",
    "    print('Val:')\n",
    "    print('Shape:', val.shape)\n",
    "    print(np.min(df.iloc[val].time_id), '->', np.max(df.iloc[val].time_id))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67617ee5-094f-44d3-9e8f-4b445aef5c37",
   "metadata": {},
   "source": [
    "1211 time ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
